# 引

机器学习（Machine Learning，ML）希望计算机从已有的数据中进行学习（找规律）。并对未知数据中进行预测。

# 机器学习基本概念

这个比较重要，初看匆匆而过，会看大道至简的感觉。

堆概念：

- 样本（Sample）：训练机器学习的基本单位。
- 特征/属性（Feature/Attribute）: 样本拥有的属性，比如CV样本中的颜色、大小等。
- 标签（label）：需要预测的值。
- 数据集（Data Set）：一组样本组成的集合。
- 训练集（Training Set）：提供模型训练的样本集合。
- 测试集（Test Set）：检验模型好坏的版本集合。
- 特征向量（Feature Vector）：<img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large [x^1,x^2,...,x^D]" style="border:none;"> 一个样本的$D$ 个特征组成的特征向量。

机器学习系统：

作为有监督学习给定个训练集
$$
\mathcal{D}=\{(x_{(1)},y_1),(x_{(2)},y_1),...,(x_{(N)},y_1)\}
$$
注：其中$x_{(1)}$ 是 $x$  组成的$D$ 维特征向量。所以一个样本应该等于特征+标签。训练集$\mathcal{D}$ 由$N$个样本组成，而每个样本应该都是**独立同分布（Identically and Independently Distributed,IID）**。IID是机器学习的**基本假设**，意思是我们的数据应该是从某个分布中**随机采样**出来的，**无偏的**，意思就是说训练数据包含了分布中所有的样本（举个例子，预测他人身高，我们假设训练数据里面有1米的，2米的，没有2米的就算有偏，听起来就不太可能对吧，吐槽国内一家鼻子朝天的小公司的面试官）。一般会默认这个设定，一般不需要进行验证，但是现实中基本**不存在IID**。

有上述前提的话，定会有一个函数集
$$
\mathcal{F=\{f_1(x),f_2(x),...\}}
$$
中有一个$f(x)$ 是个最优的。而寻找这个最优函数的过程也被称为，**学习learning**。画个图理解一下。





